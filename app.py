import av
import cv2
import numpy as np
import streamlit as st
from streamlit_webrtc import webrtc_streamer, VideoTransformerBase
from ultralytics import YOLO

# 1. à¸¥à¸­à¸‡à¹‚à¸«à¸¥à¸”à¹‚à¸¡à¹€à¸”à¸¥
try:
    # à¸›à¸£à¸±à¸š confidence à¹ƒà¸«à¹‰à¸™à¹‰à¸­à¸¢à¸¥à¸‡ (0.3) à¹€à¸žà¸·à¹ˆà¸­à¹ƒà¸«à¹‰à¸ˆà¸±à¸šà¸„à¸™à¸‡à¹ˆà¸²à¸¢à¸‚à¸¶à¹‰à¸™
    model = YOLO('yolov8n-pose.pt')
except Exception as e:
    st.error(f"à¹‚à¸«à¸¥à¸”à¹‚à¸¡à¹€à¸”à¸¥à¹„à¸¡à¹ˆà¸ªà¸³à¹€à¸£à¹‡à¸ˆ! à¹€à¸Šà¹‡à¸„à¹„à¸Ÿà¸¥à¹Œ yolov8n-pose.pt à¹ƒà¸™ GitHub à¸”à¹ˆà¸§à¸™: {e}")
    st.stop()

def calculate_angle(a, b, c):
    a = np.array(a); b = np.array(b); c = np.array(c)
    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])
    angle = np.abs(radians*180.0/np.pi)
    if angle > 180.0: angle = 360-angle
    return angle

class FitnessProcessor(VideoTransformerBase):
    def __init__(self):
        self.counter = 0
        self.stage = "down"

    def recv(self, frame):
        img = frame.to_ndarray(format="bgr24")
        img = cv2.flip(img, 1)

        # à¸ªà¸±à¹ˆà¸‡à¹ƒà¸«à¹‰ AI à¸—à¸³à¸‡à¸²à¸™ (à¸¥à¸”à¸„à¸§à¸²à¸¡à¹€à¸‚à¹‰à¸¡à¸‡à¸§à¸”à¸¥à¸‡à¹€à¸«à¸¥à¸·à¸­ 0.3)
        results = model(img, verbose=False, conf=0.3)
        
        # --- à¸ªà¹ˆà¸§à¸™à¸ªà¸³à¸„à¸±à¸: à¸§à¸²à¸”à¹€à¸ªà¹‰à¸™à¸à¸£à¸°à¸”à¸¹à¸à¸—à¸±à¸šà¸¥à¸‡à¹„à¸›à¹€à¸¥à¸¢ (à¸ˆà¸°à¹„à¸”à¹‰à¸£à¸¹à¹‰à¸§à¹ˆà¸² AI à¹€à¸«à¹‡à¸™à¹„à¸«à¸¡) ---
        img = results[0].plot() 

        try:
            # à¸”à¸¶à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ˆà¸¸à¸”à¸•à¹ˆà¸²à¸‡à¹†
            keypoints = results[0].keypoints.data[0].cpu().numpy()
            
            # à¹€à¸Šà¹‡à¸„à¸§à¹ˆà¸²à¸¡à¸­à¸‡à¹€à¸«à¹‡à¸™ à¹„à¸«à¸¥à¹ˆ(5), à¸¨à¸­à¸(7), à¸‚à¹‰à¸­à¸¡à¸·à¸­(9) à¸„à¸£à¸šà¹„à¸«à¸¡?
            if keypoints[5][2] > 0.3 and keypoints[7][2] > 0.3 and keypoints[9][2] > 0.3:
                p1 = keypoints[5][:2] # à¹„à¸«à¸¥à¹ˆ
                p2 = keypoints[7][:2] # à¸¨à¸­à¸
                p3 = keypoints[9][:2] # à¸‚à¹‰à¸­à¸¡à¸·à¸­

                angle = calculate_angle(p1, p2, p3)
                
                # Logic à¸™à¸±à¸š
                if angle > 160: self.stage = "down"
                if angle < 40 and self.stage == "down":
                    self.stage = "up"
                    self.counter += 1
                
                # à¹à¸ªà¸”à¸‡à¸ªà¸–à¸²à¸™à¸°
                cv2.putText(img, f"Angle: {int(angle)}", (20, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,0), 2)
                cv2.putText(img, f"Count: {self.counter}", (20, 120), cv2.FONT_HERSHEY_SIMPLEX, 2, (0,255,0), 4)
            else:
                 cv2.putText(img, "Show Arms Clearly!", (20, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)

        except:
            cv2.putText(img, "No Person Detected", (20, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)
        
        return av.VideoFrame.from_ndarray(img, format="bgr24")

st.title("ðŸ‹ï¸ Test Mode: Debugging")
st.write("à¸–à¹‰à¸²à¹€à¸«à¹‡à¸™à¹€à¸ªà¹‰à¸™à¸ªà¸µà¹† à¸‚à¸µà¸”à¸—à¸±à¸šà¸•à¸±à¸§à¸„à¸™ à¹à¸›à¸¥à¸§à¹ˆà¸² AI à¸—à¸³à¸‡à¸²à¸™à¹à¸¥à¹‰à¸§à¸„à¸£à¸±à¸š")
webrtc_streamer(
    key="fitness-debug",
    video_processor_factory=FitnessProcessor,
    rtc_configuration={"iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]},
    media_stream_constraints={"video": True, "audio": False}
)
